{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Pipeline\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Importer les library ====== #\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "from fonctions import findEmoji, emojiToText\n",
    "# from fonctions import normalizeCols\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== D√©terminer les path ====== #\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "parent = os.path.dirname(cwd)\n",
    "\n",
    "data_path = parent + '\\\\data\\\\'\n",
    "df_path = cwd + '\\\\dataframeTest\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(data_path + 'Test.csv')\n",
    "posts = pd.read_csv(data_path + 'Posts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Merge avec post ====== # \n",
    "df_merge = pd.merge(test, posts, left_on='postId', right_on='id', indicator=True, suffixes=('_comments', '_posts'))\n",
    "df_merge = df_merge.reset_index(drop=False).rename(columns={'index':'id'})\n",
    "df_merge = df_merge.drop(columns='_merge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Attributs de temps ====== #\n",
    "df_merge['comment_time'] = pd.to_datetime(df_merge['created_time_comments'])\n",
    "df_merge['post_time'] = pd.to_datetime(df_merge['created_time_posts'])\n",
    "df_merge = df_merge.drop(columns=['created_time_comments', 'created_time_posts'])\n",
    "\n",
    "# √âliminer les colonnes non-pertinantes\n",
    "colones_non_utiles = ['id_comments', 'parent', 'postId', 'attachments.data', 'id_posts', 'permalink_url']\n",
    "df_merge = df_merge.drop(columns=colones_non_utiles)\n",
    "df_merge.head(2)\n",
    "\n",
    "# Attribut diff√©rence de temps\n",
    "df_merge['time_difference'] = df_merge['comment_time'] - df_merge['post_time'] \n",
    "df_merge['time_difference'] = df_merge['time_difference'].astype('timedelta64[m]')\n",
    "df_merge.head(2)\n",
    "\n",
    "# Attributs temps solo\n",
    "df_merge['year'] = df_merge['comment_time'].dt.year\n",
    "df_merge['month'] = df_merge['comment_time'].dt.month\n",
    "df_merge['weekday'] = df_merge['comment_time'].dt.weekday       # Monday=0, Sunday=6\n",
    "df_merge = df_merge.drop(columns=['comment_time', 'post_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Extraire les √âmoji ====== #\n",
    "df_merge['emojis'] = df_merge['message_comments'].apply(lambda x: findEmoji(x))\n",
    "df_merge['emojis_text'] = df_merge['emojis'].apply(lambda x:[emojiToText(value) for value in x])\n",
    "\n",
    "# Attribut nombre d'√©moji\n",
    "df_merge['emoji_count'] = df_merge['emojis_text'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Subject ====== #\n",
    "# Df avec les sujet attribu√© aux articles\n",
    "df = pd.read_hdf(df_path + 'df_topics.h5')\n",
    "df_merge = pd.merge(left=df_merge, right=df, how='left', on='title')\n",
    "\n",
    "# Changer les na pour sujet = autre\n",
    "df_merge['title_classify'] = np.where(df_merge['title_classify'].isna(), 'Autre', df_merge['title_classify'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>IDENTITY_ATTACK</th>\n",
       "      <th>INSULT</th>\n",
       "      <th>PROFANITY</th>\n",
       "      <th>SEVERE_TOXICITY</th>\n",
       "      <th>THREAT</th>\n",
       "      <th>TOXICITY</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>message_comments</th>\n",
       "      <th>mainTopic</th>\n",
       "      <th>message_posts</th>\n",
       "      <th>secondTopic</th>\n",
       "      <th>shares</th>\n",
       "      <th>title</th>\n",
       "      <th>time_difference</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emojis_text</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>title_classify</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.007893</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.005419</td>\n",
       "      <td>0.006754</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon exü§î?</td>\n",
       "      <td>chroniques</td>\n",
       "      <td>CHRONIQUE / Entre 4 √† 10% des Qu√©b√©cois entend...</td>\n",
       "      <td>patrick-duquette</td>\n",
       "      <td>0</td>\n",
       "      <td>Un troupeau de voix enrag√©es</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>[ü§î]</td>\n",
       "      <td>[thinking_face]</td>\n",
       "      <td>1</td>\n",
       "      <td>√âducation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.125566</td>\n",
       "      <td>0.469236</td>\n",
       "      <td>0.501357</td>\n",
       "      <td>0.169603</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>0.434752</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Quel est ton nom ?  Je te l' ordonne de le di...</td>\n",
       "      <td>chroniques</td>\n",
       "      <td>CHRONIQUE / Entre 4 √† 10% des Qu√©b√©cois entend...</td>\n",
       "      <td>patrick-duquette</td>\n",
       "      <td>0</td>\n",
       "      <td>Un troupeau de voix enrag√©es</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>√âducation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  IDENTITY_ATTACK    INSULT  PROFANITY  SEVERE_TOXICITY    THREAT  \\\n",
       "0   0         0.000548  0.007893   0.011800         0.000517  0.005419   \n",
       "1   1         0.125566  0.469236   0.501357         0.169603  0.012389   \n",
       "\n",
       "   TOXICITY  comment_count  like_count  \\\n",
       "0  0.006754             -1           0   \n",
       "1  0.434752             -1           0   \n",
       "\n",
       "                                    message_comments   mainTopic  \\\n",
       "0                                           Mon exü§î?  chroniques   \n",
       "1  \"Quel est ton nom ?  Je te l' ordonne de le di...  chroniques   \n",
       "\n",
       "                                       message_posts       secondTopic  \\\n",
       "0  CHRONIQUE / Entre 4 √† 10% des Qu√©b√©cois entend...  patrick-duquette   \n",
       "1  CHRONIQUE / Entre 4 √† 10% des Qu√©b√©cois entend...  patrick-duquette   \n",
       "\n",
       "   shares                         title  time_difference  year  month  \\\n",
       "0       0  Un troupeau de voix enrag√©es              1.0  2023      6   \n",
       "1       0  Un troupeau de voix enrag√©es             20.0  2023      6   \n",
       "\n",
       "   weekday emojis      emojis_text  emoji_count title_classify  \n",
       "0        3    [ü§î]  [thinking_face]            1      √âducation  \n",
       "1        3     []               []            0      √âducation  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Sentiments ====== #\n",
    "df = df_merge[['message_comments']].copy()\n",
    "list_to_process = df['message_comments'].tolist()\n",
    "\n",
    "# Model\n",
    "distilled_student_sentiment_classifier = pipeline(model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\", return_all_scores=True, truncation=True)\n",
    "result_multi_student = distilled_student_sentiment_classifier(list_to_process)\n",
    "\n",
    "# Change to df\n",
    "data = [[d[\"score\"] for d in result_multi_student[i]] for i in range(len(result_multi_student))]\n",
    "col_names = ['positive', 'neutral', 'negative']\n",
    "df_multi_student = pd.DataFrame(data, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.concat([df_merge, df_multi_student], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "df_multi_student.to_hdf(df_path + 'sentiement_model_results.h5', key='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Longeur des commentaires ====== #\n",
    "df_merge['comment_lenght'] = df_merge['message_comments'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Question ====== #\n",
    "pipe = pipeline(\"text-classification\", model=\"shahrukhx01/bert-mini-finetune-question-detection\", max_length=512)\n",
    "\n",
    "sequence_to_classify = df_merge['message_comments'].tolist()\n",
    "list_classifier = pipe(sequence_to_classify, truncation=True)\n",
    "\n",
    "# Transforme to df\n",
    "question_df = pd.DataFrame(list_classifier)\n",
    "question_df = question_df.rename(columns={'label':'question_label', 'score':'question_score'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_label\n",
      "question_score\n"
     ]
    }
   ],
   "source": [
    "# Add classifer to df\n",
    "cols = question_df.columns\n",
    "\n",
    "for col in cols :\n",
    "    print(col)\n",
    "    if col not in df_merge.columns.to_list():\n",
    "        df_merge = pd.concat([df_merge, question_df], axis='columns')\n",
    "\n",
    "# Add AT\n",
    "df_merge['AT'] = df_merge['message_comments'].apply(lambda x: 1 if '@' in x else 0)\n",
    "\n",
    "df_merge['question_bool'] = np.where((df_merge['question_label'] =='LABEL_1') & (df_merge['question_score'] > 0.75), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charles_tour\\AppData\\Local\\Temp\\ipykernel_13800\\1865243409.py:1: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['message_comments', 'mainTopic', 'message_posts', 'secondTopic',\n",
      "       'title', 'emojis', 'emojis_text', 'title_classify', 'question_label'],\n",
      "      dtype='object')]\n",
      "\n",
      "  df_merge.to_hdf(df_path + 'df_merge.h5', key='s')\n"
     ]
    }
   ],
   "source": [
    "df_merge.to_hdf(df_path + 'df_merge.h5', key='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>IDENTITY_ATTACK</th>\n",
       "      <th>INSULT</th>\n",
       "      <th>PROFANITY</th>\n",
       "      <th>SEVERE_TOXICITY</th>\n",
       "      <th>THREAT</th>\n",
       "      <th>TOXICITY</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>message_comments</th>\n",
       "      <th>mainTopic</th>\n",
       "      <th>message_posts</th>\n",
       "      <th>secondTopic</th>\n",
       "      <th>shares</th>\n",
       "      <th>title</th>\n",
       "      <th>time_difference</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emojis_text</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>title_classify</th>\n",
       "      <th>comment_lenght</th>\n",
       "      <th>question_label</th>\n",
       "      <th>question_score</th>\n",
       "      <th>AT</th>\n",
       "      <th>question_bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.007893</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.005419</td>\n",
       "      <td>0.006754</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon exü§î?</td>\n",
       "      <td>chroniques</td>\n",
       "      <td>CHRONIQUE / Entre 4 √† 10% des Qu√©b√©cois entend...</td>\n",
       "      <td>patrick-duquette</td>\n",
       "      <td>0</td>\n",
       "      <td>Un troupeau de voix enrag√©es</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>[ü§î]</td>\n",
       "      <td>[thinking_face]</td>\n",
       "      <td>1</td>\n",
       "      <td>√âducation</td>\n",
       "      <td>2</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.994859</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.125566</td>\n",
       "      <td>0.469236</td>\n",
       "      <td>0.501357</td>\n",
       "      <td>0.169603</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>0.434752</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Quel est ton nom ?  Je te l' ordonne de le di...</td>\n",
       "      <td>chroniques</td>\n",
       "      <td>CHRONIQUE / Entre 4 √† 10% des Qu√©b√©cois entend...</td>\n",
       "      <td>patrick-duquette</td>\n",
       "      <td>0</td>\n",
       "      <td>Un troupeau de voix enrag√©es</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>√âducation</td>\n",
       "      <td>244</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.885108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  IDENTITY_ATTACK    INSULT  PROFANITY  SEVERE_TOXICITY    THREAT  \\\n",
       "0   0         0.000548  0.007893   0.011800         0.000517  0.005419   \n",
       "1   1         0.125566  0.469236   0.501357         0.169603  0.012389   \n",
       "\n",
       "   TOXICITY  comment_count  like_count  \\\n",
       "0  0.006754             -1           0   \n",
       "1  0.434752             -1           0   \n",
       "\n",
       "                                    message_comments   mainTopic  \\\n",
       "0                                           Mon exü§î?  chroniques   \n",
       "1  \"Quel est ton nom ?  Je te l' ordonne de le di...  chroniques   \n",
       "\n",
       "                                       message_posts       secondTopic  \\\n",
       "0  CHRONIQUE / Entre 4 √† 10% des Qu√©b√©cois entend...  patrick-duquette   \n",
       "1  CHRONIQUE / Entre 4 √† 10% des Qu√©b√©cois entend...  patrick-duquette   \n",
       "\n",
       "   shares                         title  time_difference  year  month  \\\n",
       "0       0  Un troupeau de voix enrag√©es              1.0  2023      6   \n",
       "1       0  Un troupeau de voix enrag√©es             20.0  2023      6   \n",
       "\n",
       "   weekday emojis      emojis_text  emoji_count title_classify  \\\n",
       "0        3    [ü§î]  [thinking_face]            1      √âducation   \n",
       "1        3     []               []            0      √âducation   \n",
       "\n",
       "   comment_lenght question_label  question_score  AT  question_bool  \n",
       "0               2        LABEL_1        0.994859   0              1  \n",
       "1             244        LABEL_0        0.885108   0              0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge =pd.read_hdf(df_path + 'df_merge.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeCols(df, cols):\n",
    "    for col in cols:\n",
    "        df[col]=(df[col]-df[col].min())/(df[col].max()-df[col].min())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDENTITY_ATTACK</th>\n",
       "      <th>INSULT</th>\n",
       "      <th>PROFANITY</th>\n",
       "      <th>SEVERE_TOXICITY</th>\n",
       "      <th>THREAT</th>\n",
       "      <th>TOXICITY</th>\n",
       "      <th>like_count</th>\n",
       "      <th>shares</th>\n",
       "      <th>time_difference</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>comment_lenght</th>\n",
       "      <th>AT</th>\n",
       "      <th>question_bool</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>year_2020</th>\n",
       "      <th>year_2021</th>\n",
       "      <th>year_2022</th>\n",
       "      <th>year_2023</th>\n",
       "      <th>weekday_0</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_5</th>\n",
       "      <th>weekday_6</th>\n",
       "      <th>title_classify_Autre</th>\n",
       "      <th>title_classify_COVID</th>\n",
       "      <th>title_classify_Environnement</th>\n",
       "      <th>title_classify_Justice</th>\n",
       "      <th>title_classify_Politique</th>\n",
       "      <th>title_classify_Sant√©</th>\n",
       "      <th>title_classify_Sport</th>\n",
       "      <th>title_classify_Technologie</th>\n",
       "      <th>title_classify_√âconomie</th>\n",
       "      <th>title_classify_√âducation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.007893</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.005419</td>\n",
       "      <td>0.006754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125566</td>\n",
       "      <td>0.469236</td>\n",
       "      <td>0.501357</td>\n",
       "      <td>0.169603</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>0.434752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.232092</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.008349</td>\n",
       "      <td>0.008597</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.005450</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007104</td>\n",
       "      <td>0.080892</td>\n",
       "      <td>0.077085</td>\n",
       "      <td>0.006142</td>\n",
       "      <td>0.006492</td>\n",
       "      <td>0.113367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009471</td>\n",
       "      <td>0.071433</td>\n",
       "      <td>0.011971</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.005539</td>\n",
       "      <td>0.098288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016237</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDENTITY_ATTACK    INSULT  PROFANITY  SEVERE_TOXICITY    THREAT  TOXICITY  \\\n",
       "0         0.000548  0.007893   0.011800         0.000517  0.005419  0.006754   \n",
       "1         0.125566  0.469236   0.501357         0.169603  0.012389  0.434752   \n",
       "2         0.000731  0.008349   0.008597         0.000434  0.005450  0.006723   \n",
       "3         0.007104  0.080892   0.077085         0.006142  0.006492  0.113367   \n",
       "4         0.009471  0.071433   0.011971         0.001945  0.005539  0.098288   \n",
       "\n",
       "   like_count    shares  time_difference  positive  negative  comment_lenght  \\\n",
       "0         0.0  0.000000         0.000002         0         0        0.000955   \n",
       "1         0.0  0.000000         0.000043         0         0        0.232092   \n",
       "2         0.0  0.000000         0.000804         0         0        0.010506   \n",
       "3         0.0  0.000000         0.002079         0         0        0.001910   \n",
       "4         0.0  0.000154         0.000038         0         0        0.016237   \n",
       "\n",
       "   AT  question_bool  emoji_count  year_2020  year_2021  year_2022  year_2023  \\\n",
       "0   0              1     0.001117          0          0          0          1   \n",
       "1   0              0     0.000000          0          0          0          1   \n",
       "2   0              0     0.001117          0          0          0          1   \n",
       "3   0              0     0.000000          0          0          0          1   \n",
       "4   0              0     0.001117          0          0          0          1   \n",
       "\n",
       "   weekday_0  weekday_1  weekday_2  weekday_3  weekday_4  weekday_5  \\\n",
       "0          0          0          0          1          0          0   \n",
       "1          0          0          0          1          0          0   \n",
       "2          0          0          0          0          1          0   \n",
       "3          0          0          0          0          1          0   \n",
       "4          0          0          0          1          0          0   \n",
       "\n",
       "   weekday_6  title_classify_Autre  title_classify_COVID  \\\n",
       "0          0                     0                     0   \n",
       "1          0                     0                     0   \n",
       "2          0                     0                     0   \n",
       "3          0                     0                     0   \n",
       "4          0                     0                     0   \n",
       "\n",
       "   title_classify_Environnement  title_classify_Justice  \\\n",
       "0                             0                       0   \n",
       "1                             0                       0   \n",
       "2                             0                       0   \n",
       "3                             0                       0   \n",
       "4                             0                       0   \n",
       "\n",
       "   title_classify_Politique  title_classify_Sant√©  title_classify_Sport  \\\n",
       "0                         0                     0                     0   \n",
       "1                         0                     0                     0   \n",
       "2                         0                     0                     0   \n",
       "3                         0                     0                     0   \n",
       "4                         0                     0                     0   \n",
       "\n",
       "   title_classify_Technologie  title_classify_√âconomie  \\\n",
       "0                           0                        0   \n",
       "1                           0                        0   \n",
       "2                           0                        0   \n",
       "3                           0                        0   \n",
       "4                           0                        0   \n",
       "\n",
       "   title_classify_√âducation  \n",
       "0                         1  \n",
       "1                         1  \n",
       "2                         1  \n",
       "3                         1  \n",
       "4                         1  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model = df_merge.copy()\n",
    "\n",
    "df_model = pd.get_dummies(df_model, columns = ['year', 'weekday', 'title_classify'])\n",
    "\n",
    "df_model['negative'] = 0\n",
    "df_model['positive'] = 0\n",
    "\n",
    "# Cols to keep\n",
    "col_to_keep = ['IDENTITY_ATTACK', 'INSULT', 'PROFANITY', 'SEVERE_TOXICITY', 'THREAT', 'TOXICITY', 'like_count', 'shares', 'time_difference', 'positive', 'negative', 'comment_lenght', 'AT', 'question_bool', 'emoji_count']\n",
    "# col_to_keep = ['IDENTITY_ATTACK', 'INSULT', 'PROFANITY', 'SEVERE_TOXICITY', 'THREAT', 'TOXICITY', 'like_count', 'shares', 'time_difference', 'comment_lenght', 'AT', 'question_bool', 'emoji_count']\n",
    "\n",
    "columns = ['year', 'weekday', 'title_classify']\n",
    "\n",
    "# Include hotencoded attributs\n",
    "for col in df_model.columns.to_list():\n",
    "    for column in columns:\n",
    "        if column in col:\n",
    "            col_to_keep.append(col)\n",
    "\n",
    "df_model = df_model[col_to_keep]\n",
    "\n",
    "# Au cas o√π erreur\n",
    "if  'time_difference' in col_to_keep :\n",
    "    df_model['time_difference'] = np.where(df_model['time_difference']<0, 0, df_model['time_difference'])\n",
    "\n",
    "cols = ['like_count', 'shares', 'time_difference', 'comment_lenght', 'emoji_count']\n",
    "df_model = normalizeCols(df_model, cols)\n",
    "df_model.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustements\n",
    "df_model = df_model.drop(columns='title_classify_Autre')\n",
    "df_model = df_model.drop(columns='emoji_count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDENTITY_ATTACK</th>\n",
       "      <th>INSULT</th>\n",
       "      <th>PROFANITY</th>\n",
       "      <th>SEVERE_TOXICITY</th>\n",
       "      <th>THREAT</th>\n",
       "      <th>TOXICITY</th>\n",
       "      <th>like_count</th>\n",
       "      <th>shares</th>\n",
       "      <th>time_difference</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>comment_lenght</th>\n",
       "      <th>AT</th>\n",
       "      <th>question_bool</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>year_2020</th>\n",
       "      <th>year_2021</th>\n",
       "      <th>year_2022</th>\n",
       "      <th>year_2023</th>\n",
       "      <th>weekday_0</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_5</th>\n",
       "      <th>weekday_6</th>\n",
       "      <th>title_classify_COVID</th>\n",
       "      <th>title_classify_Environnement</th>\n",
       "      <th>title_classify_Justice</th>\n",
       "      <th>title_classify_Politique</th>\n",
       "      <th>title_classify_Sant√©</th>\n",
       "      <th>title_classify_Sport</th>\n",
       "      <th>title_classify_Technologie</th>\n",
       "      <th>title_classify_√âconomie</th>\n",
       "      <th>title_classify_√âducation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.007893</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.005419</td>\n",
       "      <td>0.006754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125566</td>\n",
       "      <td>0.469236</td>\n",
       "      <td>0.501357</td>\n",
       "      <td>0.169603</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>0.434752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.232092</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDENTITY_ATTACK    INSULT  PROFANITY  SEVERE_TOXICITY    THREAT  TOXICITY  \\\n",
       "0         0.000548  0.007893   0.011800         0.000517  0.005419  0.006754   \n",
       "1         0.125566  0.469236   0.501357         0.169603  0.012389  0.434752   \n",
       "\n",
       "   like_count  shares  time_difference  positive  negative  comment_lenght  \\\n",
       "0         0.0     0.0         0.000002         0         0        0.000955   \n",
       "1         0.0     0.0         0.000043         0         0        0.232092   \n",
       "\n",
       "   AT  question_bool  emoji_count  year_2020  year_2021  year_2022  year_2023  \\\n",
       "0   0              1     0.001117          0          0          0          1   \n",
       "1   0              0     0.000000          0          0          0          1   \n",
       "\n",
       "   weekday_0  weekday_1  weekday_2  weekday_3  weekday_4  weekday_5  \\\n",
       "0          0          0          0          1          0          0   \n",
       "1          0          0          0          1          0          0   \n",
       "\n",
       "   weekday_6  title_classify_COVID  title_classify_Environnement  \\\n",
       "0          0                     0                             0   \n",
       "1          0                     0                             0   \n",
       "\n",
       "   title_classify_Justice  title_classify_Politique  title_classify_Sant√©  \\\n",
       "0                       0                         0                     0   \n",
       "1                       0                         0                     0   \n",
       "\n",
       "   title_classify_Sport  title_classify_Technologie  title_classify_√âconomie  \\\n",
       "0                     0                           0                        0   \n",
       "1                     0                           0                        0   \n",
       "\n",
       "   title_classify_√âducation  \n",
       "0                         1  \n",
       "1                         1  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Predict ====== #\n",
    "from joblib import dump, load\n",
    "model = load('randomForest.joblib')\n",
    "\n",
    "X = df_model\n",
    "prediction = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107470\n",
      "107470\n"
     ]
    }
   ],
   "source": [
    "print(len(prediction))\n",
    "print(len(df_merge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107465</th>\n",
       "      <td>107465</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107466</th>\n",
       "      <td>107466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107467</th>\n",
       "      <td>107467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107468</th>\n",
       "      <td>107468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107469</th>\n",
       "      <td>107469</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107470 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  0\n",
       "0            0  1\n",
       "1            1  0\n",
       "2            2  0\n",
       "3            3  0\n",
       "4            4  1\n",
       "...        ... ..\n",
       "107465  107465  0\n",
       "107466  107466  0\n",
       "107467  107467  0\n",
       "107468  107468  0\n",
       "107469  107469  0\n",
       "\n",
       "[107470 rows x 2 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results = pd.DataFrame(prediction)\n",
    "final_results = final_results.reset_index(drop=False)\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('finalResults.txt', final_results, fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
